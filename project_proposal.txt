Project Proposal
CMSC 22200
Jonathan Alexander
Dominick LoBraico
Laura Macaddino

For our project, we have chosen to implement a raytracing benchmark using general purpose graphics processing unit programming.

Raytracing is a computer graphics technique that is very useful for generating images with a high degree of realism. It uses an algorithm to build an image that considers both the view ray from the observer and the shadow ray of the light source on the objects within the scene. Raytracing comes at a high computational cost and is usually when the end product can be generated ahead of time. Thus, it is very useful for producing visual effects, such as reflection and dispersion, on still images and film, and it is rarely used in real-time generated images, such as in video games. C-Ray's main goal is to provide users the ability to see how well their GPU can handle raytracing. However, it is important to remember that this tool is not (yet) a measurement of how the entire system can handle generating images using raytracing, and that its results may not extroplate well to projects that require other high-level geometry or texture pulls from the system.

Individual rays share data such as scene primitives and materials, but they never modify this data. They thus do not need any synchronization during generation. Rays are fully self-contained and can be traced in parallel. 

C-Ray is a raytracing benchmark that was created by John Tsiombikas and is available for download at the following website: http://www.futuretech.blinkenlights.nl/c-ray.html. It is available to be freely modified under the GNU Public License v2. John Tisombikas created it to be an extremely simple tool, and he wrote it in as few lines of code as possible. It contains less than 2,000 lines of code is simply a measure of the float-point CPU performance. Thus, it is a CPU core benchmark test that doesn't consider the RAM or I/O speed of the system it is being run on. The code itself reads a scene file and outputs an image and the benchmark data. The rays per pixel and the height and width of the output image can both be modified in order to increase or decrease the strain on the CPU and the total testing time. Thus, we feel that this gives us access to code that is very powerful and useful but has much room for improvement as we continue to develop our project. 

We have chosen to use Nvidia's CUDA GPGPU architecture for this project. Graphics cards, already optimized for many different forms of graphics rendering seem particularly well-suited to an application like ours. The parallel throughput of a graphics processing unit, in which many threads running concurrently each at a slightly slower speed, rather than a single thread running at maximum speed, is fitting for a raytracer. Giving each ray its own thread on the GPU and letting them render concurrently should offer vast improvement gains over the current implementation of the tracer, in which each ray is generated consecutively and in the same thread.

Instead of tracing each ray sequentially, we can divide ray generation between the eight cores. On top of the parallelism of multiple cores, we can also create multiple threads per core, allowing each core to generate four rays at a time. If we plan on tracing multiple rays at a time per core, it would be wise to package four rays into a structure. Since each ray in the sequential version can be represented by 32 bytes of unsigned numbers(labelled uint32_t in the program), 4 rays would then be represented as 128 consecutive bytes of unsigned numbers. With this new implementation, any operations of the program which involve the shifting of ray bits will have to be modified accordingly. Additionally, most of the functions which accept rays as arguments will have to accept ray structures.

In addition to developing a model for parallelism, we will also have to optimize locality of the pixel data each core needs. If we do not consider locality, each time a core runs out of stored data to generate a ray, it has to fetch more data from a central location. Because it takes more time to fetch data from outside of a core than inside, the accumulated transfering of data will take up a significant amount of process time. For this reason, we must distribute all of the data necessary for each core to trace its maximum amount of rays before computations begin.

Our first parallel implementation of the raytracer will only allow each process to generate one ray at a time. After we have successfully completed this version, we will create multiple threads per core to generate rays.

Nvidia distributes a developer toolkit for use with CUDA which includes several useful tools for programming in CUDA as well as debugging code written in CUDA. The nvcc utility compiles CUDA/C or CUDA/C++ code in a format familiar to anyone who has used gcc. Similarly, CUDA-GDB is a port of another familiar UNIX tool, the GNU Debugger, and is capable of debugging both native host code as well as CUDA code. The CUDA-MEMCHECK tool provides an interface for reporting runtime execution and memory access errors. Finally, Nvidia's Visual Profiler will hopefully aid us in taming the hundreds or thousands of running threads at any moment in the execution of our application, displaying them visually and providing us with the performance details necessary to assess our progress.

Conveniently, many or all of the computers in the Linux Cluster in the Regenstein Library are equipped with GeForce GTX 260 GPUs, all capable of compiling and executing CUDA/C code. In addition, two of our personal computers are equipped with Nvidia GPUs. 
